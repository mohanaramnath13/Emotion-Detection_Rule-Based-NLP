{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Rule-Based Approach with Sliding Window + Beam Search\n",
    "This model performs emoji prediction by leveraging emotion lexicons (positive and negative), a sarcasm keyword dictionary, and a sliding window to capture contextual phrases. Beam search is applied to generate and rank possible emoji sequences, selecting the one with the highest cumulative score based on lexicon matches and context relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love pizza â†’ ðŸ˜Š\n",
      "I hate this food â†’ ðŸ¤¢\n",
      "She got me a burger â†’ ðŸ¤”\n",
      "I don't like burgers â†’ ðŸ¤”\n",
      "This is disgusting â†’ ðŸ¤¢\n",
      "I'm scared of the dark â†’ ðŸ˜¨\n",
      "He failed his test again â†’ ðŸ˜”\n",
      "Wow, that went great! â†’ ðŸ¤”\n",
      "What a nightmare â†’ ðŸ˜¨\n",
      "Iâ€™m not happy with the results â†’ ðŸ¤”\n"
     ]
    }
   ],
   "source": [
    "#model 1\n",
    "\n",
    "import re\n",
    "\n",
    "# Define lexicon mapping words to emoji sentiment scores\n",
    "emotion_lexicon = {\n",
    "    \"love\": {\"ðŸ˜Š\": 2},\n",
    "    \"like\": {\"ðŸ˜Š\": 1},\n",
    "    \"happy\": {\"ðŸ˜Š\": 2},\n",
    "    \"joy\": {\"ðŸ˜Š\": 2},\n",
    "    \"amazing\": {\"ðŸ˜Š\": 2},\n",
    "\n",
    "    \"sad\": {\"ðŸ˜”\": 2},\n",
    "    \"disappointed\": {\"ðŸ˜”\": 2},\n",
    "    \"crying\": {\"ðŸ˜”\": 3},\n",
    "    \"failed\": {\"ðŸ˜”\": 2},\n",
    "\n",
    "    \"disgusting\": {\"ðŸ¤¢\": 3},\n",
    "    \"gross\": {\"ðŸ¤¢\": 2},\n",
    "    \"yuck\": {\"ðŸ¤¢\": 3},\n",
    "    \"hate\": {\"ðŸ¤¢\": 1, \"ðŸ˜ \": 1},\n",
    "\n",
    "    \"afraid\": {\"ðŸ˜¨\": 2},\n",
    "    \"scared\": {\"ðŸ˜¨\": 2},\n",
    "    \"terrified\": {\"ðŸ˜¨\": 3},\n",
    "    \"nightmare\": {\"ðŸ˜¨\": 2},\n",
    "\n",
    "    \"angry\": {\"ðŸ˜ \": 3},\n",
    "    \"mad\": {\"ðŸ˜ \": 2},\n",
    "    \"furious\": {\"ðŸ˜ \": 3}\n",
    "}\n",
    "\n",
    "# Words indicating negation\n",
    "negation_words = [\"not\", \"don't\", \"didn't\", \"never\", \"no\"]\n",
    "\n",
    "# Preprocessing: Clean and tokenize\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r\"[^a-zA-Z0-9\\s']\", \"\", sentence)\n",
    "    tokens = sentence.split()\n",
    "    return tokens\n",
    "\n",
    "# Simple rule-based POS tagging\n",
    "def simple_pos_tag(tokens):\n",
    "    negation_words = {\"not\", \"no\", \"don't\", \"didn't\", \"isn't\", \"wasn't\", \"won't\", \"can't\", \"couldn't\"}\n",
    "    tagged = []\n",
    "    for i, word in enumerate(tokens):\n",
    "        if word in negation_words:\n",
    "            tagged.append((word, \"NEG\"))\n",
    "        else:\n",
    "            tagged.append((word, \"WORD\"))\n",
    "    return tagged\n",
    "\n",
    "\n",
    "# Emotion scoring logic with negation handling\n",
    "def get_emotion_scores(pos_tags):\n",
    "    scores = {\"ðŸ˜Š\": 0, \"ðŸ˜”\": 0, \"ðŸ¤¢\": 0, \"ðŸ˜¨\": 0, \"ðŸ˜ \": 0}\n",
    "    negate = False\n",
    "    for word, tag in pos_tags:\n",
    "        if tag == \"NEG\":\n",
    "            negate = True\n",
    "            continue\n",
    "        if word in emotion_lexicon:\n",
    "            lex = emotion_lexicon[word]\n",
    "            if negate and \"negated\" in lex:\n",
    "                for emoji, val in lex[\"negated\"].items():\n",
    "                    scores[emoji] += val\n",
    "                negate = False  # reset after using\n",
    "            elif not negate:\n",
    "                for emoji, val in lex.items():\n",
    "                    if emoji != \"negated\":\n",
    "                        scores[emoji] += val\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Beam search: pick top-k emojis\n",
    "def beam_search(scores, k=3):\n",
    "    sorted_emojis = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_emojis[:k]\n",
    "\n",
    "# Final prediction function\n",
    "def predict_emoji(sentence):\n",
    "    tokens = preprocess(sentence)\n",
    "    pos_tags = simple_pos_tag(tokens)\n",
    "    scores = get_emotion_scores(pos_tags)\n",
    "    top_emojis = beam_search(scores)\n",
    "    return top_emojis[0][0] if top_emojis[0][1] > 0 else \"ðŸ¤”\"  # fallback emoji\n",
    "\n",
    "# Sample sentences to test\n",
    "test_sentences = [\n",
    "    \"I love pizza\",\n",
    "    \"I hate this food\",\n",
    "    \"She got me a burger\",\n",
    "    \"I don't like burgers\",\n",
    "    \"This is disgusting\",\n",
    "    \"I'm scared of the dark\",\n",
    "    \"He failed his test again\",\n",
    "    \"Wow, that went great!\",\n",
    "    \"What a nightmare\",\n",
    "    \"Iâ€™m not happy with the results\"\n",
    "]\n",
    "\n",
    "# Print predictions\n",
    "for sentence in test_sentences:\n",
    "    print(f\"{sentence} â†’ {predict_emoji(sentence)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: Model 1\n",
    "The model effectively identifies basic emotional cues and works well on single-clause inputs. However, it has difficulty with complex sentence structures, especially in the presence of negation or sarcasm. The rule-based nature ensures interpretability but lacks adaptability across varied sentence constructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IMPROVED] Model 2: Enhanced Rule-Based Approach with Parse Trees & Scoped Negation\n",
    "Building upon the first model, this version integrates syntactic parsing using dependency trees, POS tagging, and emotional phrase chunking. Scoped negation is handled using dependency relations, and emotional intensity is modulated through weighted lexicons. These additions allow the model to better disambiguate emotional content in complex or sarcastic statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love pizza â†’ ðŸ˜Š\n",
      "I hate this food â†’ ðŸ¤¢\n",
      "She got me a burger â†’ ðŸ˜Š\n",
      "I don't like burgers â†’ ðŸ˜”\n",
      "This is disgusting â†’ ðŸ¤¢\n",
      "I'm scared of the dark â†’ ðŸ˜¨\n",
      "He failed his test again â†’ ðŸ˜”\n",
      "Wow, that went great! â†’ ðŸ˜Š\n",
      "What a nightmare â†’ ðŸ˜¨\n",
      "Iâ€™m not happy with the results â†’ ðŸ˜”\n"
     ]
    }
   ],
   "source": [
    "#model 2 \n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "from nltk.chunk import RegexpParser\n",
    "\n",
    "\n",
    "# Emotion to Emoji Mapping\n",
    "emoji_map = {\n",
    "    'happy': 'ðŸ˜Š',\n",
    "    'sad': 'ðŸ˜”',\n",
    "    'disgust': 'ðŸ¤¢',\n",
    "    'fear': 'ðŸ˜¨',\n",
    "    'angry': 'ðŸ˜ '\n",
    "}\n",
    "\n",
    "# Emotion Lexicon with weights\n",
    "emotion_lexicon = {\n",
    "    'happy': {'love': 2, 'like': 1, 'joy': 2, 'delicious': 1, 'great': 1, 'happy': 2, 'excited': 2},\n",
    "    'sad': {'sad': 2, 'failed': 1, 'crying': 2, 'regret': 1, 'unhappy': 2, 'disappointed': 1},\n",
    "    'disgust': {'hate': 2, 'disgusting': 3, 'gross': 2, 'yuck': 1, 'nasty': 2},\n",
    "    'fear': {'scared': 2, 'afraid': 1, 'terrified': 3, 'nightmare': 2, 'horror': 2, 'panic': 1},\n",
    "    'angry': {'angry': 2, 'furious': 3, 'mad': 2, 'annoyed': 1, 'rage': 3}\n",
    "}\n",
    "\n",
    "negations = {\"not\", \"no\", \"never\", \"don't\", \"didn't\", \"isn't\", \"wasn't\", \"aren't\", \"can't\", \"won't\"}\n",
    "\n",
    "# Sentences to test\n",
    "sentences = [\n",
    "    \"I love pizza\",\n",
    "    \"I hate this food\",\n",
    "    \"She got me a burger\",\n",
    "    \"I don't like burgers\",\n",
    "    \"This is disgusting\",\n",
    "    \"I'm scared of the dark\",\n",
    "    \"He failed his test again\",\n",
    "    \"Wow, that went great!\",\n",
    "    \"What a nightmare\",\n",
    "    \"Iâ€™m not happy with the results\"\n",
    "]\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r\"[^\\w\\s']\", \"\", sentence)\n",
    "    return sentence.split()\n",
    "\n",
    "# Use parse tree to extract relevant chunks (noun/adjective phrases)\n",
    "def get_phrases(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged = pos_tag(tokens)\n",
    "\n",
    "    grammar = r\"\"\"\n",
    "        NP: {<DT>?<JJ.*>*<NN.*>+}       # Noun phrases\n",
    "        ADJP: {<RB.?>*<JJ>}             # Adjective phrases\n",
    "    \"\"\"\n",
    "    parser = RegexpParser(grammar)\n",
    "    tree = parser.parse(tagged)\n",
    "\n",
    "    key_chunks = []\n",
    "    for subtree in tree:\n",
    "        if isinstance(subtree, Tree):\n",
    "            phrase = \" \".join(word for word, tag in subtree.leaves())\n",
    "            key_chunks.append(phrase.lower())\n",
    "    return key_chunks\n",
    "\n",
    "# Scoring with negation, weights, and phrase importance\n",
    "def score_sentence(sentence):\n",
    "    words = preprocess(sentence)\n",
    "    phrases = get_phrases(sentence)\n",
    "    score = {emotion: 0 for emotion in emoji_map}\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        is_negated = False\n",
    "        for offset in range(1, 4):\n",
    "            if i - offset >= 0 and words[i - offset] in negations:\n",
    "                is_negated = True\n",
    "                break\n",
    "\n",
    "        for emotion, keywords in emotion_lexicon.items():\n",
    "            if word in keywords:\n",
    "                base_weight = keywords[word]\n",
    "                if any(word in phrase for phrase in phrases):\n",
    "                    base_weight += 1  # boost for being in a noun/adj phrase\n",
    "                if is_negated:\n",
    "                    if emotion == 'happy':\n",
    "                        score['sad'] += base_weight\n",
    "                    elif emotion == 'sad':\n",
    "                        score['happy'] += base_weight\n",
    "                    elif emotion == 'disgust':\n",
    "                        score['happy'] += base_weight\n",
    "                    else:\n",
    "                        score[emotion] -= base_weight\n",
    "                else:\n",
    "                    score[emotion] += base_weight\n",
    "    return score\n",
    "\n",
    "# Predict using max score\n",
    "def predict_emoji(sentence):\n",
    "    scores = score_sentence(sentence)\n",
    "    best_emotion = max(scores, key=scores.get)\n",
    "    return emoji_map.get(best_emotion, 'ðŸ¤”')\n",
    "\n",
    "# Output\n",
    "for s in sentences:\n",
    "    print(f\"{s} â†’ {predict_emoji(s)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: Model 2\n",
    "This enhanced approach provides more accurate predictions, especially in inputs containing sarcasm, logical inversions, or multiple emotional clauses. Although it introduces additional computational overhead due to parse tree generation, the trade-off results in significantly improved contextual understanding and prediction accuracy compared to the first model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Conclusion\n",
    "The transition from a basic lexicon-based method to a syntactically aware rule-based system improves both precision and context handling in emoji prediction. While the current framework remains interpretable and domain-specific, it highlights the limitations of rule-based NLP for broader generalization. Future work includes implementing a data-driven architecture, such as RNNs or transformer-based models, trained on large-scale tweet-emoji datasets to enhance generalization, sarcasm detection, and emotional nuance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
